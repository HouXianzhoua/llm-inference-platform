# 支持的模型列表

| model_id | 模型名称 | 路径 | 量化方式 | 显存占用 | 状态 |
|----------|--------|------|----------|----------|------|
| qwen2-7b-instruct | Qwen2-7B-Instruct | `Qwen2-7B-Instruct-GPTQ-Int4` | GPTQ-INT4 | ~6.8GB | ✅ 已部署 |
| llama3-8b-instruct | Meta-Llama-3.1-8B-Instruct | `Meta-Llama-3.1-8B-Instruct-GPTQ-INT4` | GPTQ-INT4 | ~7.0GB | ✅ 已部署 |
