# Unified LLM Inference Gateway

åŸºäº **Text Generation Inference (TGI)** ä¸ **GPTQ é‡åŒ–æŠ€æœ¯** æ„å»ºçš„å¤šæ¨¡å‹å¤§è¯­è¨€æ¨¡å‹æ¨ç†æœåŠ¡å¹³å°ï¼Œæ”¯æŒ **Qwen2-7B-Instruct** ä¸ **Meta-Llama-3.1-8B-Instruct** çš„çƒ­åŠ è½½ã€æŒ‰éœ€åˆ‡æ¢ä¸ç»Ÿä¸€ API æ¥å…¥ã€‚

æœ¬é¡¹ç›®ä¸“ä¸ºæœ¬åœ° GPU ç¯å¢ƒï¼ˆå¦‚ RTX 4070 Super 12GBï¼‰ä¼˜åŒ–ï¼ŒåŒæ—¶å…·å¤‡å‘é˜¿é‡Œäº‘ A10/A100 ç­‰ä¼ä¸šçº§ GPU å®ä¾‹è¿ç§»çš„èƒ½åŠ›ï¼Œé€‚ç”¨äºå¤šæ¨¡å‹æœåŠ¡ã€A/B æµ‹è¯•ã€æ€§èƒ½è¯„ä¼°ç­‰åœºæ™¯ã€‚

ğŸ”§ **æ ¸å¿ƒç‰¹æ€§**  
âœ… åŒæ¨¡å‹æ”¯æŒï¼ˆQwen2 / Llama3ï¼‰GPTQ-Int4 é‡åŒ–ï¼Œæ˜¾å­˜å‹å¥½  
âœ… ç»Ÿä¸€ FastAPI ç½‘å…³ï¼ŒRESTful API æ¥å…¥  
âœ… åŠ¨æ€è·¯ç”±ï¼šé€šè¿‡ `model_id` æŒ‡å®šæ¨¡å‹ï¼Œæ”¯æŒçƒ­åˆ‡æ¢  
âœ… å¤šåœºæ™¯ Prompt æ¨¡æ¿ï¼ˆé—®ç­” / æ‘˜è¦ / æ”¹å†™ / é€šç”¨ï¼‰  
âœ… è‡ªåŠ¨é€‚é…æ¨¡å‹ä¸“ç”¨æ¨¡æ¿ï¼ˆQwen: `<|im_start|>`ï¼ŒLlama3: `<|eot_id|>`ï¼‰  
âœ… å¼‚æ­¥é«˜å¹¶å‘å¤„ç†ï¼ˆåŸºäº `httpx`ï¼‰  
âœ… å®Œæ•´ç›‘æ§ç³»ç»Ÿï¼šStatsD + InfluxDB + Grafana + GPU å®æ—¶ç›‘æ§  
âœ… Docker Compose ä¸€é”®éƒ¨ç½²ï¼Œå¼€ç®±å³ç”¨  
âœ… å¼€æºå¯å¤ç°ï¼Œæ”¯æŒæœ¬åœ°ä¸äº‘ç«¯éƒ¨ç½²  

ğŸ“Š **æ€§èƒ½è¡¨ç°ï¼ˆå‹æµ‹ç»“æœï¼‰**  
åœ¨ **100 å¹¶å‘ç”¨æˆ·ã€2ç§’ç­‰å¾…** çš„å‹åŠ›æµ‹è¯•ä¸‹ï¼ˆLocustï¼‰ï¼š

| æ¨¡å‹ | QPS | P99 å»¶è¿Ÿ |
|------|-----|----------|
| Qwen2-7B-Instruct-GPTQ-Int4 | 20 | 4.2s |
| Llama3-8B-Instruct-GPTQ-INT4 | 20 | 3.9s |

> âœ… ç³»ç»Ÿç¨³å®šï¼Œæ”¯æŒé•¿æ—¶é—´é«˜è´Ÿè½½è¿è¡Œ

ğŸš€ **å¿«é€Ÿå¯åŠ¨**
```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/yourname/llm-inference-platform.git
cd llm-inference-platform

# 2. ä¸‹è½½æ¨¡å‹ï¼ˆéœ€ Hugging Face Tokenï¼‰
huggingface-cli download Qwen/Qwen2-7B-Instruct-GPTQ-Int4 --local-dir models/Qwen2-7B-Instruct-GPTQ-Int4
huggingface-cli download hugging-quants/Meta-Llama-3.1-8B-Instruct-GPTQ-INT4 --local-dir models/Meta-Llama-3.1-8B-Instruct-GPTQ-INT4

# 3. å¯åŠ¨ç›‘æ§ç³»ç»Ÿï¼ˆStatsD + InfluxDB + Grafanaï¼‰
docker-compose -f monitoring/docker-compose.monitor.yml up -d

# 4. å¯åŠ¨æ¨ç†ç½‘å…³ä¸æ¨¡å‹æœåŠ¡
docker-compose up -d

# 5. æµ‹è¯•èŠå¤© CLIï¼ˆæ”¯æŒæ¨¡å‹åˆ‡æ¢ï¼‰
python examples/chat_cli.py
```

ğŸŒ **API æ¥å£**
```bash
POST http://localhost:8000/v1/generate
```
```json
{
  "model_id": "qwen2",
  "inputs": "ä½ å¥½ï¼Œä¸–ç•Œï¼",
  "scenario": "qa",
  "parameters": {
    "max_new_tokens": 128,
    "temperature": 0.8,
    "top_p": 0.9
  }
}
```

ğŸ“ˆ **ç›‘æ§å¯è§†åŒ–**
- è®¿é—® Grafana ä»ªè¡¨ç›˜ï¼š`http://localhost:3000`ï¼ˆè´¦å·: `admin`ï¼Œå¯†ç : `grafana`ï¼‰
- æŸ¥çœ‹ï¼šè¯·æ±‚é‡ã€å»¶è¿Ÿï¼ˆP99ï¼‰ã€QPSã€GPU åˆ©ç”¨ç‡ã€æ˜¾å­˜å ç”¨ç­‰æ ¸å¿ƒæŒ‡æ ‡

ğŸ“š **æ–‡æ¡£**
- [API è¯´æ˜](docs/API.md)
- [éƒ¨ç½²æŒ‡å—](docs/DEPLOY.md)
- [æ€§èƒ½æµ‹è¯•æŠ¥å‘Š](docs/PERFORMANCE_TEST.md)
- [é‡åŒ–æ¨¡å‹è¯´æ˜](docs/QUANTIZATION.md)

â˜ï¸ **ä¸Šäº‘å‡†å¤‡**
å·²éªŒè¯å¯è¿ç§»è‡³ **é˜¿é‡Œäº‘ A10/A100 GPU å®ä¾‹**ï¼Œè¯¦è§ [DEPLOY.md](docs/DEPLOY.md)ã€‚

---

## é¡¹ç›®ç»“æ„
```
.
â”œâ”€â”€ docker-compose.yml               # ä¸»æœåŠ¡ï¼šTGI + Gateway
â”œâ”€â”€ monitoring/                      # ç›‘æ§æ ˆï¼šInfluxDB + Grafana + StatsD + GPU ç›‘æ§
â”œâ”€â”€ gateway/                         # FastAPI ç½‘å…³æ ¸å¿ƒ
â”‚   â”œâ”€â”€ main.py                      # API è·¯ç”±ä¸è¯·æ±‚å¤„ç†
â”‚   â”œâ”€â”€ model_manager.py             # æ¨¡å‹å¥åº·æ¢æµ‹
â”‚   â”œâ”€â”€ templates.py                 # Qwen/Llama3 å¤šåœºæ™¯ Prompt æ¨¡æ¿
â”‚   â””â”€â”€ config.py                    # æ¨¡å‹æ³¨å†Œè¡¨
â”œâ”€â”€ models/                          # æœ¬åœ°æ¨¡å‹å­˜å‚¨ç›®å½•
â”œâ”€â”€ examples/                        # ç¤ºä¾‹è„šæœ¬
â”‚   â””â”€â”€ chat_cli.py                  # æ”¯æŒæ¨¡å‹åˆ‡æ¢çš„å‘½ä»¤è¡ŒèŠå¤©
â””â”€â”€ docs/                            # é¡¹ç›®æ–‡æ¡£
```

## è®¸å¯è¯
MIT License
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
