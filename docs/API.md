# ğŸ“¡ ç»Ÿä¸€æ¨ç† API æ–‡æ¡£

> æœ¬å¹³å°æä¾›ç»Ÿä¸€çš„ RESTful API æ¥å£ï¼Œæ”¯æŒå¤šæ¨¡å‹è·¯ç”±ã€åŠ¨æ€å‚æ•°æ§åˆ¶ä¸å¤šåœºæ™¯ç”Ÿæˆä»»åŠ¡ã€‚

---

## ğŸŒ åŸºç¡€ä¿¡æ¯

- **Base URL**: `http://localhost:8000`
- **åè®®**: HTTP/HTTPS
- **è®¤è¯**: æ— éœ€è®¤è¯ï¼ˆæœ¬åœ°ç¯å¢ƒï¼‰ï¼Œå¯æ‰©å±• JWT æˆ– API Key
- **Content-Type**: `application/json`
- **è¶…æ—¶è®¾ç½®**: è¯»å–è¶…æ—¶ 60sï¼ˆæ ¹æ® `max_new_tokens` è‡ªåŠ¨é€‚åº”ï¼‰

---

## ğŸ§© æ ¸å¿ƒæ¥å£

### 1. `/v1/generate` â€”â€” æ–‡æœ¬ç”Ÿæˆ
> POST ç”Ÿæˆè¡¥å…¨æˆ–æŒ‡ä»¤å“åº”ï¼Œæ”¯æŒå¤šæ¨¡å‹ã€å¤šåœºæ™¯ã€‚

#### è¯·æ±‚
- **Method**: `POST`
- **Endpoint**: `/v1/generate`
- **Body** (JSON):

| å­—æ®µ | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|------|------|------|------|
| `model_id` | string | âœ… | æ¨¡å‹æ ‡è¯†ç¬¦ï¼š`qwen2` æˆ– `llama3` |
| `inputs` | string | âœ… | è¾“å…¥æ–‡æœ¬ï¼ˆPromptï¼‰ |
| `scenario` | string | âŒ | ç”Ÿæˆåœºæ™¯ï¼š`base`ï¼ˆé»˜è®¤ï¼‰ã€`qa`ã€`summarize`ã€`rewrite` |
| `parameters` | object | âŒ | ç”Ÿæˆå‚æ•°ï¼ˆè§ä¸‹è¡¨ï¼‰ |

**`parameters` å­å­—æ®µ**ï¼š

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `max_new_tokens` | int | 128 | æœ€å¤§ç”Ÿæˆ token æ•° |
| `temperature` | float | 0.7 | é‡‡æ ·æ¸©åº¦ï¼Œæ§åˆ¶éšæœºæ€§ï¼ˆ0.0~2.0ï¼‰ |
| `top_p` | float | 0.9 | æ ¸é‡‡æ ·æ¯”ä¾‹ï¼ˆNucleus Samplingï¼‰ |
| `do_sample` | bool | true | æ˜¯å¦å¯ç”¨é‡‡æ ·ï¼ˆ`False` ä¸º greedyï¼‰ |
| `stop` | string[] | [] | è‡ªå®šä¹‰åœæ­¢å­—ç¬¦ä¸²ï¼ˆå¦‚ `["\n"]`ï¼‰ |

#### å“åº”
- **Status**: `200 OK`
- **Body** (JSON):

```json
{
  "generated_text": "ç”Ÿæˆçš„å®Œæ•´æ–‡æœ¬",
  "model": "Qwen2-7B-Instruct-GPTQ-Int4",
  "tokens": 87
}
```

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `generated_text` | string | æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ï¼ˆå·²å»é™¤ promptï¼‰ |
| `model` | string | å®é™…è°ƒç”¨çš„æ¨¡å‹åç§° |
| `tokens` | int | ç”Ÿæˆçš„ token æ•°é‡ï¼ˆä¼°ç®—ï¼‰ |

#### é”™è¯¯ç 

| çŠ¶æ€ç  | `error_code` | è¯´æ˜ |
|--------|--------------|------|
| 400 | `MODEL_NOT_FOUND` | `model_id` ä¸æ”¯æŒ |
| 400 | `PROMPT_FORMAT_FAILED` | Prompt æ¨¡æ¿æ ¼å¼åŒ–å¤±è´¥ |
| 504 | `INFERENCE_TIMEOUT` | æ¨ç†è¶…æ—¶ï¼ˆ>60sï¼‰ |
| 503 | `DOWNSTREAM_REQUEST_FAILED` | TGI æœåŠ¡ä¸å¯è¾¾ |
| 500 | `TGI_SERVER_ERROR` | TGI è¿”å›é 200 çŠ¶æ€ |

---

## ğŸ§ª ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1ï¼šåŸºç¡€å¯¹è¯ï¼ˆQwen2ï¼‰

```bash
curl http://localhost:8000/v1/generate -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "qwen2",
    "inputs": "è¯·ç”¨ä¸­æ–‡ä»‹ç»ä½ è‡ªå·±",
    "parameters": {
      "max_new_tokens": 128,
      "temperature": 0.7,
      "top_p": 0.9
    }
  }'
```

### ç¤ºä¾‹ 2ï¼šé—®ç­”ä»»åŠ¡ï¼ˆLlama3ï¼‰

```bash
curl http://localhost:8000/v1/generate -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "llama3",
    "inputs": "ç‰›é¡¿ä¸‰å¤§å®šå¾‹æ˜¯ä»€ä¹ˆï¼Ÿ",
    "scenario": "qa",
    "parameters": {
      "max_new_tokens": 200,
      "temperature": 0.5
    }
  }'
```

### ç¤ºä¾‹ 3ï¼šæ‘˜è¦ç”Ÿæˆï¼ˆQwen2ï¼‰

```bash
curl http://localhost:8000/v1/generate -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "qwen2",
    "inputs": "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œæ—¨åœ¨åˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿâ€¦â€¦",
    "scenario": "summarize",
    "parameters": {
      "max_new_tokens": 100
    }
  }'
```

### ç¤ºä¾‹ 4ï¼šå†…å®¹æ”¹å†™ï¼ˆLlama3ï¼‰

```bash
curl http://localhost:8000/v1/generate -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "llama3",
    "inputs": "è¿™ä¸ªäº§å“éå¸¸å¥½ï¼Œå¤§å®¶éƒ½å¾ˆå–œæ¬¢ã€‚",
    "scenario": "rewrite",
    "parameters": {
      "max_new_tokens": 64,
      "temperature": 0.9
    }
  }'
```

---

## ğŸ“‹ æ¨¡å‹ç®¡ç†æ¥å£

### 1. `GET /v1/models` â€”â€” åˆ—å‡ºæ‰€æœ‰æ¨¡å‹

è¿”å›æ‰€æœ‰å·²æ³¨å†Œæ¨¡å‹åŠå…¶çŠ¶æ€ã€‚

#### è¯·æ±‚
- **Method**: `GET`
- **Endpoint**: `/v1/models`

#### å“åº”
```json
{
  "models": [
    {
      "id": "qwen2",
      "name": "Qwen2-7B-Instruct-GPTQ-Int4",
      "status": "healthy",
      "supports": ["completion", "instruct"],
      "endpoint": "http://tgi-qwen2"
    },
    {
      "id": "llama3",
      "name": "Meta-Llama-3.1-8B-Instruct-GPTQ-INT4",
      "status": "healthy",
      "supports": ["completion", "instruct"],
      "endpoint": "http://tgi-llama3"
    }
  ]
}
```

---

### 2. `GET /health` â€”â€” ç®€è¦å¥åº·æ£€æŸ¥

è¿”å›æ•´ä½“å¥åº·çŠ¶æ€ã€‚

#### å“åº”ï¼ˆ200ï¼‰
```json
{
  "status": "healthy",
  "models": {
    "qwen2": "healthy",
    "llama3": "healthy"
  },
  "total": 2
}
```

### 3. `GET /health/full` â€”â€” è¯¦ç»†å¥åº·æ£€æŸ¥

å®æ—¶æ¢æµ‹æ‰€æœ‰æ¨¡å‹çŠ¶æ€ã€‚

#### å“åº”ï¼ˆ200ï¼‰
```json
{
  "status": "healthy",
  "details": {
    "qwen2": "healthy",
    "llama3": "healthy"
  },
  "total": 2,
  "healthy": 2
}
```

---

## ğŸ› ï¸ å‚æ•°è°ƒä¼˜å»ºè®®

| åœºæ™¯ | æ¨èå‚æ•° |
|------|----------|
| **ç¡®å®šæ€§è¾“å‡º**ï¼ˆå¦‚ä»£ç ç”Ÿæˆï¼‰ | `temperature=0.1`, `do_sample=False` |
| **åˆ›æ„ç”Ÿæˆ**ï¼ˆå¦‚è¯—æ­Œã€æ•…äº‹ï¼‰ | `temperature=0.9~1.5`, `top_p=0.9` |
| **æ‘˜è¦/é—®ç­”** | `temperature=0.5~0.7`, `max_new_tokens=128~256` |
| **ä½å»¶è¿Ÿæµ‹è¯•** | `max_new_tokens=32`, `temperature=0.1` |

---

## ğŸ“š è¯´æ˜

- æ‰€æœ‰æ¨¡å‹å‡ä½¿ç”¨ **GPTQ-INT4 é‡åŒ–**ï¼Œæ˜¾å­˜å ç”¨ < 7GB
- Prompt æ¨¡æ¿å·²è‡ªåŠ¨æ³¨å…¥ï¼Œæ— éœ€æ‰‹åŠ¨æ·»åŠ  `<|im_start|>` ç­‰æ ‡è®°
- æ”¯æŒè·¨åŸŸè¯·æ±‚ï¼ˆCORSï¼‰ï¼Œå‰ç«¯å¯ç›´æ¥è°ƒç”¨
- é”™è¯¯ä¿¡æ¯åŒ…å« `error_code`ï¼Œä¾¿äºå‰ç«¯å¤„ç†

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [éƒ¨ç½²æŒ‡å—](DEPLOY.md)
- [é‡åŒ–åŸç†](QUANTIZATION.md)
- [æ€§èƒ½æµ‹è¯•](PERFORMANCE_TEST.md)
- [é¡¹ç›®ä¸»é¡µ](../README.md)
