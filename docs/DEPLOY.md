# ğŸš€ éƒ¨ç½²æŒ‡å—

> æœ¬é¡¹ç›®åŸºäº **Text Generation Inference (TGI)** ä¸ **GPTQ-INT4 é‡åŒ–æŠ€æœ¯**ï¼Œæ„å»ºæ”¯æŒ `Qwen2-7B` ä¸ `Llama-3.1-8B` åŒæ¨¡å‹çš„æœ¬åœ°åŒ–å¤§è¯­è¨€æ¨¡å‹æ¨ç†å¹³å°ã€‚é€šè¿‡ FastAPI ç»Ÿä¸€ç½‘å…³è·¯ç”±è¯·æ±‚ï¼Œå¹¶é›†æˆå®Œæ•´ç›‘æ§ä½“ç³»ã€‚

---

## ğŸ§° ç¯å¢ƒè¦æ±‚

| ç»„ä»¶ | ç‰ˆæœ¬/è¦æ±‚ |
|------|----------|
| æ“ä½œç³»ç»Ÿ | Ubuntu 20.04+ on WSL2 |
| GPU | NVIDIA GPUï¼ˆæ¨è â‰¥12GB æ˜¾å­˜ï¼Œå¦‚ RTX 4070 Superï¼‰ |
| é©±åŠ¨ | NVIDIA Driver â‰¥ 535 |
| CUDA | æ”¯æŒ CUDA 12.2+ï¼ˆé€šè¿‡ WSL2 é…ç½®ï¼‰ |
| Docker | Docker Desktop for Windows + Docker Engine â‰¥ 24.0 |
| Docker Compose | â‰¥ v2.23.0 |
| ç£ç›˜ç©ºé—´ | â‰¥ 15GBï¼ˆæ¨¡å‹ + å®¹å™¨ï¼‰ |
| å†…å­˜ | â‰¥ 16GB RAMï¼ˆå»ºè®®ï¼‰ |

---

## ğŸ”½ ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡æ¨¡å‹ï¼ˆGPTQ-INT4 é‡åŒ–ç‰ˆï¼‰

ä½¿ç”¨ `git lfs` ä¸‹è½½ Hugging Face ä¸Šçš„ GPTQ é‡åŒ–æ¨¡å‹ã€‚

### 1. å®‰è£… git-lfsï¼ˆé¦–æ¬¡ï¼‰

```bash
sudo apt update && sudo apt install git-lfs -y
git lfs install
```

### 2. åˆ›å»ºæ¨¡å‹ç›®å½•å¹¶ä¸‹è½½

```bash
mkdir -p models
```

#### ä¸‹è½½ Qwen2-7B-Instruct-GPTQ-Int4

```bash
git clone https://huggingface.co/Qwen/Qwen2-7B-Instruct-GPTQ-Int4 models/Qwen2-7B-Instruct-GPTQ-Int4
```

#### ä¸‹è½½ Llama-3.1-8B-Instruct-GPTQ-INT4

```bash
git clone https://huggingface.co/hugging-quants/Meta-Llama-3.1-8B-Instruct-GPTQ-INT4 models/Meta-Llama-3.1-8B-Instruct-GPTQ-INT4
```

> ğŸ’¡ æ¨¡å‹æ€»å¤§å°çº¦ 12GBï¼Œè¯·ç¡®ä¿ç£ç›˜ç©ºé—´å……è¶³ã€‚

---

## ğŸŒ ç¬¬äºŒæ­¥ï¼šåˆ›å»ºå…±äº«ç½‘ç»œ

Docker Compose ä¸­çš„æœåŠ¡éœ€åœ¨åŒä¸€ç½‘ç»œä¸­é€šä¿¡ã€‚åˆ›å»ºä¸€ä¸ªå¤–éƒ¨ç½‘ç»œï¼š

```bash
docker network create app-network
```

> âš ï¸ ç¡®ä¿ `docker-compose.yml` ä¸­çš„ `networks.app-net.name` ä¸ä¹‹åŒ¹é…ã€‚

---

## â–¶ï¸ ç¬¬ä¸‰æ­¥ï¼šä¸€é”®å¯åŠ¨å…¨éƒ¨æœåŠ¡

é¡¹ç›®å·²æä¾› `docker-compose.yml`ï¼Œä¸€é”®å¯åŠ¨ TGI æ¨ç†æœåŠ¡ã€FastAPI ç½‘å…³ä¸ç›‘æ§ç³»ç»Ÿã€‚

### å¯åŠ¨å‘½ä»¤

```bash
docker-compose up --build
```

### æœåŠ¡è¯´æ˜

| æœåŠ¡ | ç«¯å£ | åŠŸèƒ½ |
|------|------|------|
| `tgi-qwen2` | å†…éƒ¨ 80 | Qwen2-7B-Instruct-GPTQ-Int4 æ¨ç†åç«¯ |
| `tgi-llama3` | å†…éƒ¨ 80 | Llama-3.1-8B-Instruct-GPTQ-INT4 æ¨ç†åç«¯ |
| `gateway` | `8000:8000` | ç»Ÿä¸€ API ç½‘å…³ï¼ˆFastAPIï¼‰ |
| `statsd-exporter` | 9125 | æ¥æ”¶ StatsD æŒ‡æ ‡ |
| `influxdb` | 8086 | æ—¶åºæ•°æ®åº“ |
| `grafana` | `3000:3000` | ç›‘æ§å¯è§†åŒ–é¢æ¿ |

> ğŸ• é¦–æ¬¡å¯åŠ¨è¾ƒæ…¢ï¼ˆçº¦ 3-5 åˆ†é’Ÿï¼‰ï¼Œå› éœ€åŠ è½½ä¸¤ä¸ª INT4 æ¨¡å‹è‡³ GPUã€‚

---

## ğŸ§ª ç¬¬å››æ­¥ï¼šæµ‹è¯•æ¨ç† API

### 1. åŸºç¡€æµ‹è¯•ï¼ˆcurlï¼‰

```bash
curl http://localhost:8000/v1/generate -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "qwen2",
    "inputs": "ä½ å¥½",
    "parameters": {
      "max_new_tokens": 64,
      "temperature": 0.7,
      "top_p": 0.9
    }
  }'
```

é¢„æœŸå“åº”ï¼š
```json
{
  "generated_text": "ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ",
  "model": "Qwen2-7B-Instruct-GPTQ-Int4",
  "tokens": 12
}
```

### 2. æµ‹è¯• Llama3 æ¨¡å‹

```bash
curl http://localhost:8000/v1/generate -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "llama3",
    "inputs": "Hello, how are you?",
    "parameters": {
      "max_new_tokens": 64
    }
  }'
```

### 3. ä½¿ç”¨ Python è„šæœ¬æµ‹è¯•

è¿è¡Œå†…ç½®æµ‹è¯•è„šæœ¬ï¼š

```bash
python scripts/test_api.py
```

---

## ğŸ“Š ç¬¬äº”æ­¥ï¼šè®¿é—®ç›‘æ§ç³»ç»Ÿ

### 1. Grafana å¯è§†åŒ–é¢æ¿

è®¿é—®ï¼š[http://localhost:3000](http://localhost:3000)

- **é»˜è®¤è´¦å·**ï¼š`admin`
- **é»˜è®¤å¯†ç **ï¼š`admin`ï¼ˆé¦–æ¬¡ç™»å½•åå¯ä¿®æ”¹ï¼‰

### 2. ä»ªè¡¨ç›˜åŠŸèƒ½

å·²é¢„é…ç½®ä»¥ä¸‹ç›‘æ§é¡¹ï¼š
- ğŸ“ˆ è¯·æ±‚æ€»é‡ï¼ˆ`requests.total`ï¼‰
- â±ï¸ è¯·æ±‚å»¶è¿Ÿ P95/P99ï¼ˆ`request.latency`ï¼‰
- ğŸ§  æŒ‰æ¨¡å‹ç»Ÿè®¡è¾“å…¥/è¾“å‡º token æ•°
- ğŸ”´ é”™è¯¯è¯·æ±‚è®¡æ•°ï¼ˆtimeout, model errorï¼‰

> ä»ªè¡¨ç›˜é…ç½®è§ `monitoring/grafana/dashboards/`

---

## ğŸ› ï¸ ç¬¬å…­æ­¥ï¼šå¤šåœºæ™¯æ¨ç†æµ‹è¯•

### é—®ç­”ï¼ˆQAï¼‰

```bash
curl http://localhost:8000/v1/generate -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "llama3",
    "inputs": "å…‰åˆä½œç”¨çš„åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ",
    "scenario": "qa",
    "parameters": {
      "max_new_tokens": 128,
      "temperature": 0.5
    }
  }'
```

### æ‘˜è¦ç”Ÿæˆ

```bash
curl http://localhost:8000/v1/generate -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "qwen2",
    "inputs": "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œæ—¨åœ¨åˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿâ€¦â€¦",
    "scenario": "summarize",
    "parameters": {
      "max_new_tokens": 100
    }
  }'
```

### å†…å®¹æ”¹å†™

```bash
curl http://localhost:8000/v1/generate -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "llama3",
    "inputs": "è¿™ä¸ªäº§å“éå¸¸å¥½ï¼Œå¤§å®¶éƒ½å¾ˆå–œæ¬¢ã€‚",
    "scenario": "rewrite",
    "parameters": {
      "max_new_tokens": 64,
      "temperature": 0.9
    }
  }'
```

---

## ğŸ“Š éªŒè¯èµ„æºå ç”¨

åœ¨å¦ä¸€ä¸ªç»ˆç«¯è¿è¡Œï¼š

```bash
nvidia-smi
```

åº”çœ‹åˆ°ï¼š
- GPU æ˜¾å­˜å ç”¨ **< 7.5 GB**ï¼ˆåŒæ¨¡å‹åŠ è½½ï¼‰
- è¿›ç¨‹ `docker-containerd-shim` æˆ– `python` å ç”¨ GPU
- GPU åˆ©ç”¨ç‡éšæ¨ç†è¯·æ±‚æ³¢åŠ¨

---

## ğŸ§© é…ç½®è¯´æ˜

### 1. FastAPI ç½‘å…³é…ç½®

- è·¯ç”±é€»è¾‘ï¼š`gateway/main.py`
- æ¨¡å‹æ³¨å†Œè¡¨ï¼š`gateway/config.py`
- Prompt æ¨¡æ¿ï¼š`gateway/templates.py`
- æ—¥å¿—ä¸ç›‘æ§ï¼šé›†æˆ `statsd` + `logging`

### 2. TGI å¯åŠ¨å‚æ•°

| å‚æ•° | è¯´æ˜ |
|------|------|
| `--quantize=gptq` | å¯ç”¨ GPTQ INT4 é‡åŒ– |
| `--trust-remote-code` | å…è®¸åŠ è½½ Qwen/Llama3 è‡ªå®šä¹‰ä»£ç  |
| `--max-input-length` | æœ€å¤§è¾“å…¥é•¿åº¦ |
| `--max-total-tokens` | æ€»ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆKV Cacheï¼‰ |
| `--cuda-memory-fraction` | é™åˆ¶ GPU æ˜¾å­˜ä½¿ç”¨æ¯”ä¾‹ï¼ˆQwen2 è®¾ç½®ä¸º 0.6ï¼‰ |

---

## ğŸ”„ åç»­æ‰©å±•

- âœ… **æ”¯æŒæ›´å¤šæ¨¡å‹**ï¼šåªéœ€åœ¨ `models/` æ·»åŠ æ¨¡å‹ï¼Œå¹¶æ›´æ–° `config.py`
- âœ… **è¿ç§»åˆ°äº‘ç¯å¢ƒ**ï¼šæ”¯æŒé˜¿é‡Œäº‘ A10/A100 å®ä¾‹ï¼Œåªéœ€ä¿®æ”¹ `docker-compose.yml`
- âœ… **æ€§èƒ½ä¼˜åŒ–**ï¼šå¯ç”¨ `--cuda-graphs`ã€`--max-batch-size` ç­‰é«˜çº§å‚æ•°
- âœ… **å‰ç«¯ç•Œé¢**ï¼šå¯å¯¹æ¥ Gradio æˆ–è‡ªå®šä¹‰ Web UI

---

## ğŸ“š å‚è€ƒæ–‡æ¡£

- [ç»Ÿä¸€ API æ–‡æ¡£](API.md)
- [GPTQ é‡åŒ–åŸç†](QUANTIZATION.md)
- [æ€§èƒ½æµ‹è¯•æŒ‡å—](PERFORMANCE_TEST.md)
- [é¡¹ç›®ä¸»é¡µ](../README.md)
