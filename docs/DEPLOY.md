# ğŸš€ éƒ¨ç½²æŒ‡å—

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•åœ¨æœ¬åœ°ç¯å¢ƒï¼ˆWSL2 + NVIDIA GPUï¼‰ä¸Šéƒ¨ç½²åŸºäº Text Generation Inference (TGI) çš„å¤§è¯­è¨€æ¨¡å‹æ¨ç†æœåŠ¡ï¼Œæ”¯æŒ GPTQ é‡åŒ–æ¨¡å‹çš„é«˜æ•ˆè¿è¡Œã€‚

**å½“å‰å·²éªŒè¯æ”¯æŒæ¨¡å‹ï¼š**
- `Qwen/Qwen2-7B-Instruct-GPTQ-Int4`

**åç»­å°†æ‰©å±•æ”¯æŒï¼š**
- `hugging-quants/Meta-Llama-3.1-8B-Instruct-GPTQ-INT4`

---

## ğŸ§° ç¯å¢ƒè¦æ±‚

| ç»„ä»¶ | ç‰ˆæœ¬/è¦æ±‚ |
|------|----------|
| æ“ä½œç³»ç»Ÿ | Ubuntu 20.04+ on WSL2 |
| GPU | NVIDIA GPUï¼ˆæ¨è 12GB+ æ˜¾å­˜ï¼Œå¦‚ RTX 4070 Superï¼‰ |
| é©±åŠ¨ | NVIDIA Driver â‰¥ 535 |
| CUDA | æ”¯æŒ CUDA 12.2+ï¼ˆé€šè¿‡ WSL2 é…ç½®ï¼‰ |
| Docker | Docker Desktop for Windows + Docker Engine â‰¥ 24.0 |
| Docker Compose | â‰¥ v2.23.0 |
| ç£ç›˜ç©ºé—´ | â‰¥ 10GBï¼ˆç”¨äºæ¨¡å‹ç¼“å­˜ï¼‰ |

---

## ğŸ”½ 1. ä¸‹è½½æ¨¡å‹ï¼ˆGPTQ-Int4 é‡åŒ–ç‰ˆï¼‰

ä½¿ç”¨ `git lfs` å…‹éš† Hugging Face ä¸Šçš„ GPTQ é‡åŒ–æ¨¡å‹ï¼š

```bash
# åˆ›å»ºæ¨¡å‹ç›®å½•
mkdir -p models

# ä¸‹è½½ Qwen2-7B-Instruct-GPTQ-Int4
git lfs install
git clone https://huggingface.co/Qwen/Qwen2-7B-Instruct-GPTQ-Int4 models/Qwen2-7B-Instruct-GPTQ-Int4
---

## â–¶ï¸ 2. å¯åŠ¨ TGI æ¨ç†æœåŠ¡

ä½¿ç”¨æä¾›çš„è„šæœ¬å¯åŠ¨ Qwen2 æ¨¡å‹æœåŠ¡ï¼š

```bash
./scripts/start-tgi-qwen.sh
```

è¯¥è„šæœ¬å†…å®¹å¦‚ä¸‹ï¼š

```bash
#!/bin/bash
docker run --rm \
  --gpus all \
  --shm-size 1g \
  -p 8080:80 \
  -v $PWD/models/Qwen2-7B-Instruct-GPTQ-Int4:/data \
  ghcr.io/huggingface/text-generation-inference:latest \
  --model-id /data \
  --quantize gptq \
  --max-input-length 2048 \
  --max-total-tokens 4096 \
  --trust-remote-code
```

### å‚æ•°è¯´æ˜ï¼š
- `--quantize gptq`: å¯ç”¨ GPTQ INT4 é‡åŒ–æ¨ç†
- `--trust-remote-code`: å…è®¸åŠ è½½ Qwen è‡ªå®šä¹‰æ¨¡å‹ä»£ç 
- `--max-*`: æ§åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦ä¸æ˜¾å­˜ä½¿ç”¨
- `-v`: å°†æœ¬åœ°æ¨¡å‹ç›®å½•æŒ‚è½½åˆ°å®¹å™¨å†…

æœåŠ¡å¯åŠ¨åå°†åœ¨ `http://localhost:8080` æä¾› API æ¥å£ã€‚

---

## ğŸ§ª 3. æµ‹è¯•æ¨ç† API

### æ–¹æ³•ä¸€ï¼šä½¿ç”¨ curl

```bash
curl http://localhost:8080/generate \
    -X POST \
    -H "Content-Type: application/json" \
    -d '{
        "inputs": "<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n<|im_start|>user\nè¯·ç”¨ä¸­æ–‡ä»‹ç»ä½ è‡ªå·±ã€‚<|im_end|>\n<|im_start|>assistant\n",
        "parameters": {
            "max_new_tokens": 128,
            "temperature": 0.7,
            "top_p": 0.9,
            "return_full_text": false
        }
    }'
```

### æ–¹æ³•äºŒï¼šä½¿ç”¨ Python è„šæœ¬

è¿è¡Œæµ‹è¯•è„šæœ¬ï¼š

```bash
python scripts/test_api.py
```

é¢„æœŸè¾“å‡ºç¤ºä¾‹ï¼š
```json
{
  "generated_text": "æˆ‘æ˜¯é€šä¹‰åƒé—®ï¼Œç”±é˜¿é‡Œäº‘ç ”å‘çš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹â€¦â€¦"
}
```

> âš ï¸ æ³¨æ„ï¼šQwen2 ä½¿ç”¨ç‰¹æ®Šçš„ prompt æ ¼å¼ï¼Œè¯·ç¡®ä¿è¾“å…¥ç¬¦åˆ `<|im_start|>role\ncontent<|im_end|>` ç»“æ„ã€‚

---

## ğŸ“Š 4. éªŒè¯èµ„æºå ç”¨

åœ¨å¦ä¸€ä¸ªç»ˆç«¯è¿è¡Œï¼š

```bash
nvidia-smi
```

åº”çœ‹åˆ°ï¼š
- GPU æ˜¾å­˜å ç”¨ **< 7GB**
- è¿›ç¨‹ `docker-containerd-shim` æˆ– `python` å ç”¨ GPU

---

## ğŸ§© åç»­æ­¥éª¤

ä¸‹ä¸€æ­¥å°†ï¼š
1. éƒ¨ç½²ç¬¬äºŒä¸ªæ¨¡å‹ï¼šLlama-3.1-8B-Instruct-GPTQ-INT4
2. æ„å»º FastAPI ç½‘å…³ï¼Œå®ç°å¤šæ¨¡å‹è·¯ç”±
3. è‡ªåŠ¨åŒ– prompt æ¨¡æ¿é€‚é…

è¯¦è§ [QUANTIZATION.md](QUANTIZATION.md) äº†è§£ GPTQ é‡åŒ–åŸç†ã€‚
```

---


